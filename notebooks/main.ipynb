{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from scipy.spatial import ConvexHull, distance_matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib.patches import Ellipse\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       texture3                                                            \\\n",
      "          count       mean       std    min     25%    50%     75%    max   \n",
      "target                                                                      \n",
      "N         148.0  30.353176  6.226169  17.04  26.275  30.40  33.835  49.54   \n",
      "R          46.0  29.623913  5.555203  16.67  26.105  29.47  33.090  40.14   \n",
      "\n",
      "       smoothness3            ... texture1        texture2            \\\n",
      "             count      mean  ...      75%    max    count      mean   \n",
      "target                        ...                                      \n",
      "N            148.0  0.143479  ...  25.0975  39.28    148.0  1.296551   \n",
      "R             46.0  0.145341  ...  24.1625  30.99     46.0  1.200233   \n",
      "\n",
      "                                                            \n",
      "             std     min       25%     50%      75%    max  \n",
      "target                                                      \n",
      "N       0.554712  0.4489  0.923475  1.1720  1.56675  3.503  \n",
      "R       0.426360  0.3621  0.965225  1.1855  1.36925  2.910  \n",
      "\n",
      "[2 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# 1-mean, 2-se, 3-worst\n",
    "data = pd.read_csv('breast_data.csv')\n",
    "\n",
    "# Columns of interest\n",
    "cols = ['texture3', 'smoothness3', 'symmetry1', 'texture1', 'texture2']\n",
    "\n",
    "# Check if all columns exist\n",
    "missing_cols = [col for col in cols if col not in data.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Missing columns in the dataset: {missing_cols}\")\n",
    "else:\n",
    "    # Group by label (assuming 'target' is the label column)\n",
    "    grouped_stats = data.groupby('target')[cols].describe()\n",
    "    print(grouped_stats)\n",
    "    grouped_stats.to_csv(\"grouped_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# # fetch dataset \n",
    "# breast_cancer_wisconsin_original = fetch_ucirepo(id=16) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = breast_cancer_wisconsin_original.data.features \n",
    "# y = breast_cancer_wisconsin_original.data.targets \n",
    "\n",
    "# # Merge features with target for a single DataFrame\n",
    "# df = X.copy()\n",
    "# df['target'] = y\n",
    "\n",
    "# # Drop rows with any missing values\n",
    "# df.dropna(inplace=True)\n",
    "\n",
    "# # Convert all integer columns to float\n",
    "# for col in df.select_dtypes(include='int'):\n",
    "#     df[col] = df[col].astype(float)\n",
    "\n",
    "# # Save original dataset to CSV\n",
    "# df.to_csv(\"breast_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dataset\n",
    "# breast = pd.read_csv('breast_data.csv')\n",
    "\n",
    "# # Normalize all numeric columns to [0, 1]\n",
    "# breast_normalized = (breast - breast.min()) / (breast.max() - breast.min())\n",
    "# breast_normalized = breast_normalized.round(3)\n",
    "\n",
    "# label = 'target'\n",
    "# label_values = breast_normalized[label].tolist()\n",
    "\n",
    "# breast_normalized = breast_normalized.drop(columns=label)\n",
    "# breast_normalized.to_csv(\"breast_normalized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0%\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 683...\n",
      "Computing P-values for point 500 of 683...\n",
      "Iteration 10: error is 15.604348\n",
      "Iteration 20: error is 13.493839\n",
      "Iteration 30: error is 12.707357\n",
      "Iteration 40: error is 12.470548\n",
      "Iteration 50: error is 12.453668\n",
      "Iteration 60: error is 12.484795\n",
      "Iteration 70: error is 12.513403\n",
      "Iteration 80: error is 12.526636\n",
      "Iteration 90: error is 12.538362\n",
      "Iteration 100: error is 12.534348\n",
      "Iteration 110: error is 1.240207\n",
      "Iteration 120: error is 0.881974\n",
      "Iteration 130: error is 0.743806\n",
      "Iteration 140: error is 0.682344\n",
      "Iteration 150: error is 0.648372\n",
      "Iteration 160: error is 0.627317\n",
      "Iteration 170: error is 0.612827\n",
      "Iteration 180: error is 0.602840\n",
      "Iteration 190: error is 0.596058\n",
      "Iteration 200: error is 0.590609\n",
      "Iteration 210: error is 0.586596\n",
      "Iteration 220: error is 0.583455\n",
      "Iteration 230: error is 0.580700\n",
      "Iteration 240: error is 0.578391\n",
      "Iteration 250: error is 0.576669\n",
      "Iteration 260: error is 0.575214\n",
      "Iteration 270: error is 0.573925\n",
      "Iteration 280: error is 0.572738\n",
      "Iteration 290: error is 0.571519\n",
      "Iteration 300: error is 0.570553\n",
      "Iteration 310: error is 0.569810\n",
      "Iteration 320: error is 0.569195\n",
      "Iteration 330: error is 0.568700\n",
      "Iteration 340: error is 0.568327\n",
      "Iteration 350: error is 0.568044\n",
      "Iteration 360: error is 0.567823\n",
      "Iteration 370: error is 0.567639\n",
      "Iteration 380: error is 0.567474\n",
      "Iteration 390: error is 0.567327\n",
      "Iteration 400: error is 0.567202\n",
      "Iteration 410: error is 0.567094\n",
      "Iteration 420: error is 0.567001\n",
      "Iteration 430: error is 0.566919\n",
      "Iteration 440: error is 0.566844\n",
      "Iteration 450: error is 0.566780\n",
      "Iteration 460: error is 0.566712\n",
      "Iteration 470: error is 0.566651\n",
      "Iteration 480: error is 0.566605\n",
      "Iteration 490: error is 0.566568\n",
      "Iteration 500: error is 0.566535\n",
      "Iteration 510: error is 0.566505\n",
      "Iteration 520: error is 0.566478\n",
      "Iteration 530: error is 0.566453\n",
      "Iteration 540: error is 0.566431\n",
      "Iteration 550: error is 0.566412\n",
      "Iteration 560: error is 0.566394\n",
      "Iteration 570: error is 0.566378\n",
      "Iteration 580: error is 0.566361\n",
      "Iteration 590: error is 0.566346\n",
      "Iteration 600: error is 0.566333\n",
      "Iteration 610: error is 0.566320\n",
      "Iteration 620: error is 0.566309\n",
      "Iteration 630: error is 0.566300\n",
      "Iteration 640: error is 0.566291\n",
      "Iteration 650: error is 0.566283\n",
      "Iteration 660: error is 0.566275\n",
      "Iteration 670: error is 0.566268\n",
      "Iteration 680: error is 0.566261\n",
      "Iteration 690: error is 0.566255\n",
      "Iteration 700: error is 0.566250\n",
      "Iteration 710: error is 0.566244\n",
      "Iteration 720: error is 0.566239\n",
      "Iteration 730: error is 0.566234\n",
      "Iteration 740: error is 0.566230\n",
      "Iteration 750: error is 0.566225\n",
      "Iteration 760: error is 0.566221\n",
      "Iteration 770: error is 0.566217\n",
      "Iteration 780: error is 0.566214\n",
      "Iteration 790: error is 0.566210\n",
      "Iteration 800: error is 0.566207\n",
      "Iteration 810: error is 0.566204\n",
      "Iteration 820: error is 0.566201\n",
      "Iteration 830: error is 0.566198\n",
      "Iteration 840: error is 0.566195\n",
      "Iteration 850: error is 0.566193\n",
      "Iteration 860: error is 0.566190\n",
      "Iteration 870: error is 0.566188\n",
      "Iteration 880: error is 0.566185\n",
      "Iteration 890: error is 0.566183\n",
      "Iteration 900: error is 0.566181\n",
      "Iteration 910: error is 0.566179\n",
      "Iteration 920: error is 0.566177\n",
      "Iteration 930: error is 0.566175\n",
      "Iteration 940: error is 0.566173\n",
      "Iteration 950: error is 0.566172\n",
      "Iteration 960: error is 0.566170\n",
      "Iteration 970: error is 0.566168\n",
      "Iteration 980: error is 0.566167\n",
      "Iteration 990: error is 0.566165\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 683...\n",
      "Computing P-values for point 500 of 683...\n",
      "Computing gradients for point 0\n",
      "Computing gradients for point 1\n",
      "Computing gradients for point 2\n",
      "Computing gradients for point 3\n",
      "Computing gradients for point 4\n",
      "Computing gradients for point 5\n",
      "Computing gradients for point 6\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# generate tangent map\n",
    "!python /Users/jiahaoxu/Github/gxdr/backend/funcs/TangentMap.py {'breast_normalized.csv'} tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'breast_normalized_TangentMap_tsne.tmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbreast_normalized_TangentMap_tsne.tmap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m data_import \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m      4\u001b[0m tmap \u001b[38;5;241m=\u001b[39m data_import\n",
      "File \u001b[0;32m~/Github/gxdr/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'breast_normalized_TangentMap_tsne.tmap'"
     ]
    }
   ],
   "source": [
    "f = open(\"breast_normalized_TangentMap_tsne.tmap\", \"r\")\n",
    "\n",
    "data_import = json.loads(f.read())\n",
    "tmap = data_import\n",
    "print(len(tmap[0]['tangent'][0]))\n",
    "\n",
    "data = {}\n",
    "\n",
    "for i, tangent in enumerate(tmap):\n",
    "    print(sum(tangent['tangent'][1]))\n",
    "    tangent['class'] = label_values[i]\n",
    "    tangent['label'] = False\n",
    "\n",
    "data['tmap'] = tmap\n",
    "\n",
    "data['Col_labels'] = breast_normalized.columns.tolist()\n",
    "\n",
    "print(data['tmap'][0])\n",
    "print(data['Col_labels'])\n",
    "\n",
    "# Save the JSON string to a .tmap file\n",
    "with open(\"breast_cancer.tmap\", 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
